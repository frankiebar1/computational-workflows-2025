{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great, now that we discussed a little let's continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the current approach utilized by the authors lacks reproducibility, we will explore an alternative method by leveraging nf-core pipelines for data analysis.\n",
    "\n",
    "Please explain, how we will achieve reproducibility for the course  with this approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the strict guidelines and standardized operations applied in pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully downloaded 2 of the fastq files we will use in our study.\n",
    "\n",
    "What is the next step if we want to first have a count table and check the quality of our fastq files? What is the pipeline called to do so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is called rnaseq (https://nf-co.re/rnaseq/). To run this we need to prepare the sample sheet and make it match the example the authors show. Next the pipeline is ran with the following command:\n",
    "nextflow run nf-core/rnaseq \\\n",
    "    --input <SAMPLESHEET> \\\n",
    "    --outdir <OUTDIR> \\\n",
    "    --gtf <GTF> \\\n",
    "    --fasta <GENOME FASTA> \\\n",
    "    -profile <docker/singularity/.../institute>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the 2 files using an nf-core pipeline.\n",
    "\n",
    "What does this pipeline do?\n",
    "\n",
    "Which are the main tools that will be used in the pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has these steps:\n",
    "\n",
    "    1 Merge re-sequenced FastQ files (cat)\n",
    "    2 Auto-infer strandedness by subsampling and pseudoalignment (fq, Salmon)\n",
    "    3 Read QC (FastQC)\n",
    "    4 UMI extraction (UMI-tools)\n",
    "    5 Adapter and quality trimming (Trim Galore!)\n",
    "    6 Removal of genome contaminants (BBSplit)\n",
    "    7 Removal of ribosomal RNA (SortMeRNA)\n",
    "    8 Choice of multiple alignment and quantification routes (For STAR the sentieon implementation can be chosen):\n",
    "        STAR -> Salmon\n",
    "        STAR -> RSEM\n",
    "        HiSAT2 -> NO QUANTIFICATION\n",
    "    9 Sort and index alignments (SAMtools)\n",
    "    10 UMI-based deduplication (UMI-tools)\n",
    "    11 Duplicate read marking (picard MarkDuplicates)\n",
    "    12 Transcript assembly and quantification (StringTie)\n",
    "    13 Create bigWig coverage files (BEDTools, bedGraphToBigWig)\n",
    "    14 Extensive quality control:\n",
    "        RSeQC\n",
    "        Qualimap\n",
    "        dupRadar\n",
    "        Preseq\n",
    "        DESeq2\n",
    "        Kraken2 -> Bracken on unaligned sequences; optional\n",
    "    15 Pseudoalignment and quantification (Salmon or ‘Kallisto’; optional)\n",
    "    16 Present QC for raw read, alignment, gene biotype, sample similarity, and strand-specificity checks (MultiQC, R)\n",
    "\n",
    "The tools are present in the previous list in brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all other nf-core pipelines, the chosen pipeline takes in a samplesheet as input.\n",
    "\n",
    "Use Python and pandas to create the samplesheet for your 2 samples. Feel free to make use of the table you created earlier today.\n",
    "\n",
    "Choose your sample names wisely, they must be the connection of the results to the metadata. If you can't find the sample in the metadata later, the analysis was useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post here the command you used to run nf-core/rnaseq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sampleSheet = pd.read_csv(\"fetchngs-out/samplesheet/samplesheet.csv\")\n",
    "sampleSheet = sampleSheet[['sample', 'fastq_1', 'fastq_2', 'strandedness']]\n",
    "sampleSheet.to_csv(\"samplesheet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain all the parameters you set and why you set them in this way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    profile docker\n",
    "    samplesheet\n",
    "    gtf file from ncbi (reference) or --genome  GRCm38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browsing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the pipeline perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the quality control steps. Are you happy with the quality and why. If not, why not.\n",
    "Please give additional information on : \n",
    "- ribosomal rRNA\n",
    "- Duplication\n",
    "- GC content\n",
    "\n",
    "What are the possible steps that could lead to poorer results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality control starts by merging any technical replicates and checking the library’s strandedness. Raw reads are assessed with FastQC to check quality, adapter contamination, and base composition. FastQC also analyses GC content to reveal any bias or strong deviation between samples to exclude those that could be affected by technical artifacts. Low quality bases and adapters are trimmed and ribosomal RNA sequences are filtered out. The cleaned reads are then aligned, sorted and indexed, with duplicates marked. Tools RSeQC, Qualimap, dupRadar, and Preseq are used to check alignment quality, coverage, strand specificity and duplication levels. Finally, MultiQC combines all results into one report so sample quality and consistency can be reviewed easily.\n",
    "\n",
    "All steps could lead to poorer results as they are based on thresholds which if set incorrectly may filter out too much or too little of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you exclude any samples? If yes, which and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 2 and 4 should be excluded because of their projections in pca: they are very far away to all the other samples which are all clustered together. If we removed these samples, pca could more accurately capture what we expect to be real variance between the other samples rather than some noise we are not interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would you now do to continue the experiment? What are the scientists trying to figure out? Which packages on R or python would you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to perform differential expression analysis. The objective is to discover differentially expressed genes in different groups leading to further understanding on chronic pain and treatment response. We could use packages such as ggVennDiagram and pheatmap in R to visualize the results. Matplotlib or Plotly could be used in Python to show plots such as volcano plots or MA plots to show genes that are differentially expressed and have a valid p value. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwbd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
